{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "**Paper:** Automatic identification of Hainan Gibbon calls in passive acoustic recordings\n",
    "\n",
    "**Authors:** Emmanuel Dufourq, Ian Durbach, James Hansford, Sam Turvey, Amanda Hoepfner\n",
    "\n",
    "**Code Date:** April 2020\n",
    "\n",
    "**Repository:** https://github.com/emmanueldufourq/GibbonClassifier\n",
    "\n",
    "**Notebook description:** Predict on a single .wav audio file.\n",
    "\n",
    "_Please refer to the user manual for further details of the operations being executed in this notebook._\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Note 1: Set colab=True if executing on Google Colab, or set colab=False if running locally.**\n",
    "\n",
    "**Note 2: When running on Google Colab, please select Kernel > ...........**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    !pip install SoundFile\n",
    "    from google.colab import drive\n",
    "    from pydrive.auth import GoogleAuth\n",
    "    from pydrive.drive import GoogleDrive\n",
    "    from google.colab import auth\n",
    "    from oauth2client.client import GoogleCredentials\n",
    "    import tarfile\n",
    "\n",
    "    # Google Authentication\n",
    "    auth.authenticate_user()\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.credentials = GoogleCredentials.get_application_default()\n",
    "    drive = GoogleDrive(gauth)\n",
    "\n",
    "    # Download data files\n",
    "    downloaded = drive.CreateFile({'id':\"1u7orJHwGOMIcyqwiiEl2e7KEZpnT_0h7\"})\n",
    "    downloaded.GetContentFile('GibbonClassifierData.tar.gz')\n",
    "\n",
    "    # Extract files to temporary location in Google Drive\n",
    "    with tarfile.open('GibbonClassifierData.tar.gz', 'r:gz') as tar:\n",
    "        tar.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla K80, pci bus id: 0001:00:00.0, compute capability: 3.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from CNN_Network import *\n",
    "from Predict_Helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_file = 'HGSM3B_0+1_20160308_055700.wav'\n",
    "testing_folder = 'Raw_Data/Test/'\n",
    "prediction_folder = 'Predictions/'\n",
    "weights_name = 'pretrained_weights_from_paper.hdf5'\n",
    "location_model = \"Experiments/\"\n",
    "time_to_extract = 10\n",
    "sample_rate = 4800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "These correspond to the output for file 3 in the research article.\n",
    "\n",
    "The correct values for this file are as follows: [3676 3795], [14759 14955], [19557 20257], [20533 20856]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading audio file (this can take some time)...\n",
      "\n",
      "Reading done.\n",
      "Processing batch: 0 out of 8\n",
      "(3591, 48000)\n",
      "Processing batch: 1 out of 8\n",
      "(3600, 48000)\n",
      "Processing batch: 2 out of 8\n",
      "(3600, 48000)\n",
      "Processing batch: 3 out of 8\n",
      "(3600, 48000)\n",
      "Processing batch: 4 out of 8\n",
      "(3600, 48000)\n",
      "Processing batch: 5 out of 8\n",
      "(3600, 48000)\n",
      "Processing batch: 6 out of 8\n",
      "(3600, 48000)\n",
      "Processing batch: 7 out of 8\n",
      "(3600, 48000)\n",
      "---------------------------------------------------\n",
      "Predicted segment start and end times:\n",
      "[[3623, 3802], [14752, 14962], [19365, 20262], [20526, 20860]]\n"
     ]
    }
   ],
   "source": [
    "execute_processing(testing_folder, testing_file, sample_rate,\n",
    "                      location_model, weights_name, time_to_extract, prediction_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python gibbons_env",
   "language": "python",
   "name": "gibbons_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
